<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Kaiyan Zhang (张开颜) </title> <meta name="author" content="Kaiyan Zhang"> <meta name="description" content="This is homepage for Kaiyan. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iseesaw.github.io/"> <script src="/assets/js/theme.js?b3cb7e13f309fa753cd044e2ae1ff937"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Kaiyan Zhang (张开颜) </h1> <p class="desc">PhD Candidate, <a href="https://www.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Tsinghua University</a></p> </header> <article> <div class="profile float-right"> </div> <div class="clearfix"> <p>I am a final-year PhD candidate at the Department of Electronic Engineering, Tsinghua University, under the guidance of Professor <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=h3Nsz6YAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Bowen Zhou</a>. I earned B.S. (2020) and M.S. (2022) degrees in Computer Science and Technology from the Harbin Institute of Technology (HIT), where I was supervised by <a href="https://scholar.google.com/citations?user=DBLdEf4AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Weinan Zhang</a> and <a href="https://scholar.google.com/citations?user=zyMJ1V0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Ting Liu</a> in the <a href="https://ir.hit.edu.cn/" rel="external nofollow noopener" target="_blank">HIT-SCIR</a> lab.</p> <p>My current passion is pushing the boundaries of domain-specific superintelligence (called <a href="https://arxiv.org/pdf/2407.08642" rel="external nofollow noopener" target="_blank">ExpertAGI</a>), enabling AI systems to achieve expert-level reasoning and collaboration across high-value and practical scenarios. My research directions include:</p> <ul> <li> <p><strong>Scalable Learning (e.g., RL):</strong> Developing novel frameworks for scalable reinforcement learning, such as <a href="https://github.com/PRIME-RL/TTRL" rel="external nofollow noopener" target="_blank">TTRL</a> (test-time RL with unlabeled data), <a href="https://github.com/TsinghuaC3I/SSRL" rel="external nofollow noopener" target="_blank">SSRL</a> (self-search RL leveraging intrinsic model capabilities), <a href="https://github.com/TsinghuaC3I/MARTI" rel="external nofollow noopener" target="_blank">MARTI</a> (multi-agent RL coordination), and <a href="https://openreview.net/pdf?id=fGIqGfmgkW" rel="external nofollow noopener" target="_blank">OpenPRM</a> (scalable process reward modeling), all aiming to reduce supervision costs and unlock self-improving LLMs.</p> </li> <li> <p><strong>Collaborative Intelligence:</strong> Designing mechanisms for model cooperation and synergy, including <a href="https://arxiv.org/abs/2310.15477" rel="external nofollow noopener" target="_blank">CRaSh</a> (efficient fine-tuning via clustering and sharing), <a href="https://arxiv.org/abs/2403.03129" rel="external nofollow noopener" target="_blank">CoGenesis</a> (secure collaboration between large and small models), <a href="https://arxiv.org/abs/2406.12295" rel="external nofollow noopener" target="_blank">FS-Gen</a> (unified laws in collaborative decoding), and <a href="https://github.com/TsinghuaC3I/MARTI" rel="external nofollow noopener" target="_blank">MARTI</a>, to empower collective intelligence among agents.</p> </li> <li> <p><strong>Scientific Intelligence:</strong> Applying LLMs to scientific discovery, with projects like <a href="https://github.com/TsinghuaC3I/UltraMedical" rel="external nofollow noopener" target="_blank">UltraMedical</a> (generalist biomedical models), <a href="https://arxiv.org/abs/2311.05965" rel="external nofollow noopener" target="_blank">hypothesis proposer</a> (autonomous scientific hypothesis generation), and <a href="https://arxiv.org/abs/2508.10308" rel="external nofollow noopener" target="_blank">ReviewRL</a> (reinforcement learning for automated scientific review), advancing AI’s role in research and innovation.</p> </li> </ul> <p>Expect to graduate in June 2026. My CV is <a href="/assets/pdf/cv.pdf">here</a>.</p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%7A%68%61%6E%67-%6B%79%32%32@%6D%61%69%6C%73.%74%73%69%6E%67%68%75%61.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=3RjM7L8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/iseesaw" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/OkhayIea" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Please feel free to contact me via email. </div> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 20vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan 26, 2026</th> <td> Five papers are accepted to ICLR 2026, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 19, 2025</th> <td> <a href="https://github.com/PRIME-RL/TTRL" rel="external nofollow noopener" target="_blank">TTRL</a><img src="https://img.shields.io/github/stars/PRIME-RL/TTRL" alt=""> was accepted to NeurIPS 2025, Congratulations! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 11, 2025</th> <td> Excited to share our new survey paper on <a href="https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs" rel="external nofollow noopener" target="_blank">RL for Large Reasoning Models</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/Awesome-RL-for-LRMs" alt="">. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 21, 2025</th> <td> One paper is accepted to EMNLP 2025 (see <a href="https://github.com/TsinghuaC3I/MARTI/tree/main/examples/reviewrl" rel="external nofollow noopener" target="_blank">ReviewRL</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 15, 2025</th> <td> We investigate agentic search RL without reliance on external search engine while maintaining strong sim2real generalization. (see <a href="https://github.com/TsinghuaC3I/SSRL" rel="external nofollow noopener" target="_blank">SSRL</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/SSRL" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 26, 2025</th> <td> Two papers are accepted to ICCV 2025, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">May 27, 2025</th> <td> We are very excited to release MARTI: A framework for LLM-based Multi-Agent Reinforced Training and Inference. (see <a href="https://github.com/TsinghuaC3I/MARTI" rel="external nofollow noopener" target="_blank">MARTI</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/MARTI" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">May 16, 2025</th> <td> Two papers are accepted to ACL 2025 Main, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">May 14, 2025</th> <td> Just shared our latest work on TTS, RL and TTRL at <a href="http://qingkeai.online/archives/sE5qOogK" rel="external nofollow noopener" target="_blank">QingkeTalk</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 02, 2025</th> <td> Four papers are accepted to ICML 2025, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 23, 2025</th> <td> We release Test-time Reinforcement Learning (TTRL), which investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in LLMs. (see <a href="https://github.com/PRIME-RL/TTRL" rel="external nofollow noopener" target="_blank">TTRL</a> <img src="https://img.shields.io/github/stars/PRIME-RL/TTRL" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 31, 2025</th> <td> We release collections of RL recipes (see <a href="https://github.com/TsinghuaC3I/Awesome-RL-Reasoning-Recipes" rel="external nofollow noopener" target="_blank">Awesome-RL-Reasoning-Recipes</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/Awesome-RL-Reasoning-Recipes" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 24, 2025</th> <td> Video-T1 is released, which firstly evaluate TTS on video generation (see <a href="https://github.com/liuff19/Video-T1" rel="external nofollow noopener" target="_blank">Video-T1</a> <img src="https://img.shields.io/github/stars/liuff19/Video-T1" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 10, 2025</th> <td> We explore compute-optimal test-time scaling (see <a href="https://github.com/RyanLiu112/compute-optimal-tts" rel="external nofollow noopener" target="_blank">compute-optimal-tts</a> <img src="https://img.shields.io/github/stars/RyanLiu112/compute-optimal-tts" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 23, 2025</th> <td> One first-author paper is accepted to ICLR 2025 (see <a href="https://openreview.net/forum?id=fGIqGfmgkW" rel="external nofollow noopener" target="_blank">OpenPRM</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 24, 2024</th> <td> One paper is accepted to AAAI 2025 (Congrats to Xinwei). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 27, 2024</th> <td> One first-author paper is accepted to NeurIPS 2024 D&amp;B Track (see <a href="https://github.com/TsinghuaC3I/UltraMedical" rel="external nofollow noopener" target="_blank">UltraMedical</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/UltraMedical" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 20, 2024</th> <td> One paper is accepted to EMNLP 2024 (see <a href="https://github.com/TsinghuaC3I/LPA" rel="external nofollow noopener" target="_blank">LPA</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 10, 2024</th> <td> One co-first author paper is accepted to COLM 2024 (see <a href="https://github.com/TsinghuaC3I/LLM4BioHypoGen" rel="external nofollow noopener" target="_blank">LLM4BioHypoGen</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">May 16, 2024</th> <td> Two papers are accepted to ACL 2024 (One first-author, see <a href="https://github.com/TsinghuaC3I/CoGenesis" rel="external nofollow noopener" target="_blank">CoGenesis</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 13, 2024</th> <td> One paper is accepted to NAACL 2024 (see <a href="https://github.com/Xuekai-Zhu/pad" rel="external nofollow noopener" target="_blank">PAD</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 06, 2023</th> <td> One first-author paper is accepted to EMNLP 2023 (see <a href="https://github.com/TsinghuaC3I/CRaSh" rel="external nofollow noopener" target="_blank">CRaSh</a>). </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="RL4LRM" class="col-sm-8"> <div class="title">A Survey of Reinforcement Learning for Large Reasoning Models</div> <div class="author"> Shijie Wang<sup>*</sup>, Pengfei Li<sup>*</sup>, Yikun Fu<sup>*</sup>, Kaifeng Liu, Fangyuan Li, Yang Liu, Xiaowei Sun, Zonglin Li, Siyao Zhao, Jian Zhao, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Kai Tian, Dong Li, Junqi Gao, Yutong Zhang, Yiqun Chen, Yuqiang Li, Zoe Li, Weinan Zhang, Peng Ye, Shuyue Hu, Lei Bai&lt;sup&gt;†&lt;/sup&gt;, Bowen Zhou&lt;sup&gt;†&lt;/sup&gt;, Kaiyan Zhang&lt;sup&gt;†&lt;/sup&gt;, Biqing Qi&lt;sup&gt;†&lt;/sup&gt;' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Corresponding author"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2602.07848" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/MARTI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="RL4LRN" class="col-sm-8"> <div class="title">A Survey of Reinforcement Learning for Large Reasoning Models</div> <div class="author"> <em>Kaiyan Zhang<sup>*†</sup></em>, Yuxin Zuo<sup>*†</sup>, Bingxiang He<sup>*</sup>, Youbang Sun<sup>*</sup>, Runze Liu<sup>*</sup>, Che Jiang<sup>*</sup>, Yuchen Fan<sup>*</sup>, Kai Tian<sup>*</sup>, Guoli Jia<sup>*</sup>, Pengfei Li<sup>*</sup>, and <span class="more-authors" title="click to view 29 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '29 more authors' ? 'Yu Fu&lt;sup&gt;*&lt;/sup&gt;, Xingtai Lv&lt;sup&gt;*&lt;/sup&gt;, Yuchen Zhang&lt;sup&gt;*&lt;/sup&gt;, Sihang Zeng&lt;sup&gt;*&lt;/sup&gt;, Shang Qu&lt;sup&gt;*&lt;/sup&gt;, Haozhan Li&lt;sup&gt;*&lt;/sup&gt;, Shijie Wang&lt;sup&gt;*&lt;/sup&gt;, Yuru Wang&lt;sup&gt;*&lt;/sup&gt;, Xinwei Long, Fangfu Liu, Xiang Xu, Jiaze Ma, Xuekai Zhu, Ermo Hua, Yihao Liu, Zonglin Li, Huayu Chen, Xiaoye Qu, Yafu Li, Weize Chen, Zhenzhao Yuan, Junqi Gao, Dong Li, Zhiyuan Ma, Ganqu Cui, Zhiyuan Liu, Biqing Qi, Ning Ding, Bowen Zhou' : '29 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">29 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Core contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2509.08827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2025</abbr> </div> <div id="ReviewRL" class="col-sm-8"> <div class="title">ReviewRL: Towards Automated Scientific Review with RL</div> <div class="author"> Sihang Zeng<sup>*</sup>, Kai Tian<sup>*</sup>, <em>Kaiyan Zhang<sup>*</sup></em>, Junqi Gao, Runze Liu, Sa Yang, Jingxuan Li, Xinwei Long, Jiaheng Ma, Biqing Qi, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Bowen Zhou' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>The 2025 Conference on Empirical Methods in Natural Language Processing</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2508.10308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/MARTI/tree/main/examples/reviewrl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="SSRL" class="col-sm-8"> <div class="title">SSRL: Self-Search Reinforcement Learning</div> <div class="author"> Yuchen Fan<sup>*</sup>, <em>Kaiyan Zhang<sup>*†</sup></em>, Heng Zhou<sup>*</sup>, Yuxin Zuo, Yanxu Chen, Yu Fu, Xinwei Long, Xuekai Zhu, Che Jiang, Yuchen Zhang, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Li Kang, Gang Chen, Cheng Huang, Zhizhou He, Bingning Wang, Lei Bai, Ning Ding, Bowen Zhou' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2508.10874" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/SSRL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR 2026</abbr> </div> <div id="MARTI" class="col-sm-8"> <div class="title">MARTI: A Framework for Multi-Agent LLM Systems Reinforced Training and Inference</div> <div class="author"> <em>Kaiyan Zhang<sup>*†</sup></em>, Runze Liu<sup>*</sup>, Xuekai Zhu<sup>*</sup>, Kai Tian<sup>*</sup>, Sihang Zeng<sup>*</sup>, Guoli Jia<sup>*</sup>, Yuchen Fan<sup>*</sup>, Xingtai Lv<sup>*</sup>, Yuxin Zuo<sup>*</sup>, Che Jiang<sup>*</sup>, and <span class="more-authors" title="click to view 16 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '16 more authors' ? 'Ziyang Liu, Jianyu Wang, Yuru Wang, Ruotong Zhao, Ermo Hua, Yibo Wang, Shijie Wang, Junqi Gao, Xinwei Long, Youbang Sun, Zhiyuan Ma, Ganqu Cui, Lei Bai, Ning Ding, Biqing Qi, Bowen Zhou' : '16 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">16 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Core contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>The Fourteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=E7jZqo0A50" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/MARTI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS 2025</abbr> </div> <div id="TTRL" class="col-sm-8"> <div class="title">TTRL: Test-Time Reinforcement Learning</div> <div class="author"> Yuxin Zuo<sup>*</sup>, <em>Kaiyan Zhang<sup>*†</sup></em>, Shang Qu, Li Sheng, Xuekai Zhu, Biqing Qi, Youbang Sun, Ganqu Cui<sup>†</sup>, Ning Ding, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>The Thirty-Ninth Annual Conference on Neural Information Processing Systems</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2504.16084" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PRIME-RL/TTRL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR 2025</abbr> </div> <div id="zhang2024towards" class="col-sm-8"> <div class="title">OpenPRM: Building Open-domain Process-based Reward Models with Preference Trees</div> <div class="author"> <em>Kaiyan Zhang</em>, Jiayuan Zhang, Haoxin Li, Xuekai Zhu, Ermo Hua, Xingtai Lv, Ning Ding, Biqing Qi, and Bowen Zhou </div> <div class="periodical"> <em>The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=fGIqGfmgkW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="zhang2024towardt" class="col-sm-8"> <div class="title">Towards Building Specialized Generalist AI with System 1 and System 2 Fusion</div> <div class="author"> <em>Kaiyan Zhang<sup>*</sup></em>, Biqing Qi<sup>*</sup>, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2407.08642" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML@MAS 2025</abbr> </div> <div id="zhang2024fast" class="col-sm-8"> <div class="title">Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding</div> <div class="author"> <em>Kaiyan Zhang<sup>*</sup></em>, Jianyu Wang<sup>*</sup>, Ning Ding, Biqing Qi, Ermo Hua, Xingtai Lv, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>ICML 2025 Workshop on MAS</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2406.12295" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/FS-GEN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS 2024</abbr> </div> <div id="zhang2024ultramedical" class="col-sm-8"> <div class="title">Ultramedical: Building specialized generalists in biomedicine</div> <div class="author"> <em>Kaiyan Zhang</em>, Sihang Zeng, Ermo Hua, Ning Ding, Zhang-Ren Chen, Zhiyuan Ma, Haoxin Li, Ganqu Cui, Biqing Qi, Xuekai Zhu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2406.03949" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/UltraMedical" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACL 2024</abbr> </div> <div id="zhang2024cogenesis" class="col-sm-8"> <div class="title">CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following</div> <div class="author"> <em>Kaiyan Zhang</em>, Jianyu Wang, Ermo Hua, Biqing Qi, Ning Ding, and Bowen Zhou </div> <div class="periodical"> <em>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2403.03129" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/CoGenesis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">COLM 2024</abbr> </div> <div id="qi2024large" class="col-sm-8"> <div class="title">Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation</div> <div class="author"> Biqing Qi<sup>*</sup>, <em>Kaiyan Zhang<sup>*</sup></em>, Kai Tian, Haoxiang Li, Zhang-Ren Chen, Sihang Zeng, Ermo Hua, Hu Jinfang, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>First Conference on Language Modeling</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2407.08940" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/LLM4BioHypoGen" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2023</abbr> </div> <div id="zhang2023crash" class="col-sm-8"> <div class="title">CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model</div> <div class="author"> <em>Kaiyan Zhang</em>, Ning Ding, Biqing Qi, Xuekai Zhu, Xinwei Long, and Bowen Zhou </div> <div class="periodical"> <em>Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2310.15477" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/CRaSh" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Kaiyan Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 19, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-H7E2SD4PMT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-H7E2SD4PMT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"news-one-first-author-paper-is-accepted-to-emnlp-2023-see-crash",title:"One first-author paper is accepted to EMNLP 2023 (see CRaSh).",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-naacl-2024-see-pad",title:"One paper is accepted to NAACL 2024 (see PAD).",description:"",section:"News"},{id:"news-two-papers-are-accepted-to-acl-2024-one-first-author-see-cogenesis",title:"Two papers are accepted to ACL 2024 (One first-author, see CoGenesis).",description:"",section:"News"},{id:"news-one-co-first-author-paper-is-accepted-to-colm-2024-see-llm4biohypogen",title:"One co-first author paper is accepted to COLM 2024 (see LLM4BioHypoGen).",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-emnlp-2024-see-lpa",title:"One paper is accepted to EMNLP 2024 (see LPA).",description:"",section:"News"},{id:"news-one-first-author-paper-is-accepted-to-neurips-2024-d-amp-amp-b-track-see-ultramedical",title:"One first-author paper is accepted to NeurIPS 2024 D&amp;amp;B Track (see UltraMedical )....",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-aaai-2025-congrats-to-xinwei",title:"One paper is accepted to AAAI 2025 (Congrats to Xinwei).",description:"",section:"News"},{id:"news-one-first-author-paper-is-accepted-to-iclr-2025-see-openprm",title:"One first-author paper is accepted to ICLR 2025 (see OpenPRM).",description:"",section:"News"},{id:"news-we-explore-compute-optimal-test-time-scaling-see-compute-optimal-tts",title:"We explore compute-optimal test-time scaling (see compute-optimal-tts ).",description:"",section:"News"},{id:"news-video-t1-is-released-which-firstly-evaluate-tts-on-video-generation-see-video-t1",title:"Video-T1 is released, which firstly evaluate TTS on video generation (see Video-T1 )....",description:"",section:"News"},{id:"news-we-release-collections-of-rl-recipes-see-awesome-rl-reasoning-recipes",title:"We release collections of RL recipes (see Awesome-RL-Reasoning-Recipes ).",description:"",section:"News"},{id:"news-we-release-test-time-reinforcement-learning-ttrl-which-investigates-reinforcement-learning-rl-on-data-without-explicit-labels-for-reasoning-tasks-in-llms-see-ttrl",title:"We release Test-time Reinforcement Learning (TTRL), which investigates Reinforcement Learning (RL) on data...",description:"",section:"News"},{id:"news-four-papers-are-accepted-to-icml-2025-congrats-to-the-collaborators",title:"Four papers are accepted to ICML 2025, congrats to the collaborators.",description:"",section:"News"},{id:"news-just-shared-our-latest-work-on-tts-rl-and-ttrl-at-qingketalk",title:"Just shared our latest work on TTS, RL and TTRL at QingkeTalk.",description:"",section:"News"},{id:"news-two-papers-are-accepted-to-acl-2025-main-congrats-to-the-collaborators",title:"Two papers are accepted to ACL 2025 Main, congrats to the collaborators.",description:"",section:"News"},{id:"news-we-are-very-excited-to-release-marti-a-framework-for-llm-based-multi-agent-reinforced-training-and-inference-see-marti",title:"We are very excited to release MARTI: A framework for LLM-based Multi-Agent Reinforced...",description:"",section:"News"},{id:"news-two-papers-are-accepted-to-iccv-2025-congrats-to-the-collaborators",title:"Two papers are accepted to ICCV 2025, congrats to the collaborators.",description:"",section:"News"},{id:"news-we-investigate-agentic-search-rl-without-reliance-on-external-search-engine-while-maintaining-strong-sim2real-generalization-see-ssrl",title:"We investigate agentic search RL without reliance on external search engine while maintaining...",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-emnlp-2025-see-reviewrl",title:"One paper is accepted to EMNLP 2025 (see ReviewRL).",description:"",section:"News"},{id:"news-excited-to-share-our-new-survey-paper-on-rl-for-large-reasoning-models",title:"Excited to share our new survey paper on RL for Large Reasoning Models...",description:"",section:"News"},{id:"news-ttrl-was-accepted-to-neurips-2025-congratulations",title:"TTRL was accepted to NeurIPS 2025, Congratulations!",description:"",section:"News"},{id:"news-five-papers-are-accepted-to-iclr-2026-congrats-to-the-collaborators",title:"Five papers are accepted to ICLR 2026, congrats to the collaborators.",description:"",section:"News"},{id:"projects-project-template",title:"project template",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/template/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%68%61%6E%67-%6B%79%32%32@%6D%61%69%6C%73.%74%73%69%6E%67%68%75%61.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=3RjM7L8AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iseesaw","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/OkhayIea","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>