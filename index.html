<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Kaiyan Zhang (张开颜) </title> <meta name="author" content="Kaiyan Zhang"> <meta name="description" content="This is homepage for Kaiyan. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iseesaw.github.io/"> <script src="/assets/js/theme.js?b3cb7e13f309fa753cd044e2ae1ff937"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Kaiyan Zhang (张开颜) </h1> <p class="desc">PhD Candidate, <a href="https://www.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Tsinghua University</a></p> </header> <article> <div class="profile float-right"> </div> <div class="clearfix"> <p>I am a third-year PhD student at the Department of Electronic Engineering, Tsinghua University, under the guidance of Professor <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=h3Nsz6YAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Bowen Zhou</a>. I previously earned a Master’s degree in Computer Science and Technology in 2022 from the Harbin Institute of Technology (HIT), where I was supervised by <a href="https://scholar.google.com/citations?user=DBLdEf4AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Weinan Zhang</a> and <a href="https://scholar.google.com/citations?user=zyMJ1V0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Ting Liu</a> in the HIT-SCIR lab.</p> <p>My research centers on the alignment and collaboration of large language models (LLMs), with the broader goal of building <strong>scalable collaborative intelligence systems</strong>. I am currently developing an LLM-based multi-agent reinforcement learning framework to enhance reasoning capabilities beyond foundational levels (R1 and O1). My work also explores how multiple agents can effectively collaborate on real-world, agentic tasks.</p> <p>I am open to collaborations and discussions across related areas—such as <strong>multi-agent</strong> (<a href="https://arxiv.org/pdf/2407.08940" rel="external nofollow noopener" target="_blank">COLM 2024</a>, <a href="https://arxiv.org/pdf/2403.03129" rel="external nofollow noopener" target="_blank">ACL 2024</a>, <a href="https://arxiv.org/pdf/2406.12295" rel="external nofollow noopener" target="_blank">Arxiv 2406</a>), <strong>reinforcement learning</strong> (<a href="https://arxiv.org/pdf/2412.01981" rel="external nofollow noopener" target="_blank">Arxiv 2412 - ImplicitPRM</a>, <a href="https://arxiv.org/pdf/2502.01456" rel="external nofollow noopener" target="_blank">Arxiv 2502 - PRIME</a>), <strong>test-time scaling</strong> (<a href="https://openreview.net/forum?id=fGIqGfmgkW" rel="external nofollow noopener" target="_blank">ICLR 2025 - OpenPRM</a>, <a href="https://arxiv.org/pdf/2502.06703?" rel="external nofollow noopener" target="_blank">Arxiv 2502</a>, <a href="https://arxiv.org/pdf/2503.18942" rel="external nofollow noopener" target="_blank">Arxiv 2503 - Video-T1</a>, <a href="https://arxiv.org/pdf/2504.00891" rel="external nofollow noopener" target="_blank">Arxiv 2504 - GenPRM</a>), <strong>test-time reinforcement learning</strong> (<a href="https://arxiv.org/abs/2504.16084" rel="external nofollow noopener" target="_blank">Arxiv 2504 - TTRL</a>), and <strong>multi-agent reinforcement learning</strong> (<a href="https://github.com/TsinghuaC3I/MARTI" rel="external nofollow noopener" target="_blank">GitHub 2025 - MARTI</a>). I’d be happy to connect with researchers who share these interests.</p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%7A%68%61%6E%67-%6B%79%32%32@%6D%61%69%6C%73.%74%73%69%6E%67%68%75%61.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=3RjM7L8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/iseesaw" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/OkhayIea" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Please feel free to contact me via email. </div> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 20vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 27, 2025</th> <td> We are very excited to release MARTI: A framework for LLM-based Multi-Agent Reinforced Training and Inference. (see <a href="https://github.com/TsinghuaC3I/MARTI" rel="external nofollow noopener" target="_blank">MARTI</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/MARTI" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">May 16, 2025</th> <td> Two papers are accepted to ACL 2025 Main, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">May 14, 2025</th> <td> Just shared our latest work on TTS, RL and TTRL at <a href="http://qingkeai.online/archives/sE5qOogK" rel="external nofollow noopener" target="_blank">QingkeTalk</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 02, 2025</th> <td> Four papers are accepted to ICML 2025, congrats to the collaborators. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 23, 2025</th> <td> We release Test-time Reinforcement Learning (TTRL), which investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in LLMs. (see <a href="https://github.com/PRIME-RL/TTRL" rel="external nofollow noopener" target="_blank">TTRL</a> <img src="https://img.shields.io/github/stars/PRIME-RL/TTRL" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 31, 2025</th> <td> We release collections of RL recipes (see <a href="https://github.com/TsinghuaC3I/Awesome-RL-Reasoning-Recipes" rel="external nofollow noopener" target="_blank">Awesome-RL-Reasoning-Recipes</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/Awesome-RL-Reasoning-Recipes" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 24, 2025</th> <td> Video-T1 is released, which firstly evaluate TTS on video generation (see <a href="https://github.com/liuff19/Video-T1" rel="external nofollow noopener" target="_blank">Video-T1</a> <img src="https://img.shields.io/github/stars/liuff19/Video-T1" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 10, 2025</th> <td> We explore compute-optimal test-time scaling (see <a href="https://github.com/RyanLiu112/compute-optimal-tts" rel="external nofollow noopener" target="_blank">compute-optimal-tts</a> <img src="https://img.shields.io/github/stars/RyanLiu112/compute-optimal-tts" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 23, 2025</th> <td> One first-author paper is accepted to ICLR 2025 (see <a href="https://openreview.net/forum?id=fGIqGfmgkW" rel="external nofollow noopener" target="_blank">OpenPRM</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 24, 2024</th> <td> One paper is accepted to AAAI 2025 (Congrats to Xinwei). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 27, 2024</th> <td> One first-author paper is accepted to NeurIPS 2024 D&amp;B Track (see <a href="https://github.com/TsinghuaC3I/UltraMedical" rel="external nofollow noopener" target="_blank">UltraMedical</a> <img src="https://img.shields.io/github/stars/TsinghuaC3I/UltraMedical" alt="">). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 20, 2024</th> <td> One paper is accepted to EMNLP 2024 (see <a href="https://github.com/TsinghuaC3I/LPA" rel="external nofollow noopener" target="_blank">LPA</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 10, 2024</th> <td> One co-first author paper is accepted to COLM 2024 (see <a href="https://github.com/TsinghuaC3I/LLM4BioHypoGen" rel="external nofollow noopener" target="_blank">LLM4BioHypoGen</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">May 16, 2024</th> <td> Two papers are accepted to ACL 2024 (One first-author, see <a href="https://github.com/TsinghuaC3I/CoGenesis" rel="external nofollow noopener" target="_blank">CoGenesis</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 13, 2024</th> <td> One paper is accepted to NAACL 2024 (see <a href="https://github.com/Xuekai-Zhu/pad" rel="external nofollow noopener" target="_blank">PAD</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 06, 2023</th> <td> One first-author paper is accepted to EMNLP 2023 (see <a href="https://github.com/TsinghuaC3I/CRaSh" rel="external nofollow noopener" target="_blank">CRaSh</a>). </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">GitHub</abbr> </div> <div id="MARTI" class="col-sm-8"> <div class="title">MARTI: A Framework for Multi-Agent LLM Systems Reinforced Training and Inference</div> <div class="author"> <em>Kaiyan Zhang<sup>*†</sup></em>, Runze Liu<sup>*</sup>, Xuekai Zhu<sup>*</sup>, Kai Tian<sup>*</sup>, Sihang Zeng<sup>*</sup>, Guoli Jia<sup>*</sup>, Yuchen Fan<sup>*</sup>, Xingtai Lv<sup>*</sup>, Yuxin Zuo<sup>*</sup>, Che Jiang<sup>*</sup>, and <span class="more-authors" title="click to view 16 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '16 more authors' ? 'Ziyang Liu, Jianyu Wang, Yuru Wang, Ruotong Zhao, Ermo Hua, Yibo Wang, Shijie Wang, Junqi Gao, Xinwei Long, Youbang Sun, Zhiyuan Ma, Ganqu Cui, Lei Bai, Ning Ding, Biqing Qi, Bowen Zhou' : '16 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">16 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Core contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>GitHub</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/TsinghuaC3I/MARTI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="TTRL" class="col-sm-8"> <div class="title">TTRL: Test-Time Reinforcement Learning</div> <div class="author"> Yuxin Zuo<sup>*</sup>, <em>Kaiyan Zhang<sup>*†</sup></em>, Shang Qu, Li Sheng, Xuekai Zhu, Biqing Qi, Youbang Sun, Ganqu Cui<sup>†</sup>, Ning Ding, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Project Lead"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2504.16084" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PRIME-RL/TTRL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR 2025</abbr> </div> <div id="zhang2024towards" class="col-sm-8"> <div class="title">OpenPRM: Building Open-domain Process-based Reward Models with Preference Trees</div> <div class="author"> <em>Kaiyan Zhang</em>, Jiayuan Zhang, Haoxin Li, Xuekai Zhu, Ermo Hua, Xingtai Lv, Ning Ding, Biqing Qi, and Bowen Zhou </div> <div class="periodical"> <em>The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=fGIqGfmgkW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="zhang2024towardt" class="col-sm-8"> <div class="title">Towards Building Specialized Generalist AI with System 1 and System 2 Fusion</div> <div class="author"> <em>Kaiyan Zhang<sup>*</sup></em>, Biqing Qi<sup>*</sup>, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2407.08642" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="zhang2024fast" class="col-sm-8"> <div class="title">Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding</div> <div class="author"> <em>Kaiyan Zhang<sup>*</sup></em>, Jianyu Wang<sup>*</sup>, Ning Ding, Biqing Qi, Ermo Hua, Xingtai Lv, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>Preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2406.12295" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/FS-GEN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS 2024</abbr> </div> <div id="zhang2024ultramedical" class="col-sm-8"> <div class="title">Ultramedical: Building specialized generalists in biomedicine</div> <div class="author"> <em>Kaiyan Zhang</em>, Sihang Zeng, Ermo Hua, Ning Ding, Zhang-Ren Chen, Zhiyuan Ma, Haoxin Li, Ganqu Cui, Biqing Qi, Xuekai Zhu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2406.03949" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/UltraMedical" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACL 2024</abbr> </div> <div id="zhang2024cogenesis" class="col-sm-8"> <div class="title">CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following</div> <div class="author"> <em>Kaiyan Zhang</em>, Jianyu Wang, Ermo Hua, Biqing Qi, Ning Ding, and Bowen Zhou </div> <div class="periodical"> <em>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2403.03129" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/CoGenesis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">COLM 2024</abbr> </div> <div id="qi2024large" class="col-sm-8"> <div class="title">Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation</div> <div class="author"> Biqing Qi<sup>*</sup>, <em>Kaiyan Zhang<sup>*</sup></em>, Kai Tian, Haoxiang Li, Zhang-Ren Chen, Sihang Zeng, Ermo Hua, Hu Jinfang, and Bowen Zhou <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution"> </i> </div> <div class="periodical"> <em>First Conference on Language Modeling</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2407.08940" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/LLM4BioHypoGen" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2023</abbr> </div> <div id="zhang2023crash" class="col-sm-8"> <div class="title">CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model</div> <div class="author"> <em>Kaiyan Zhang</em>, Ning Ding, Biqing Qi, Xuekai Zhu, Xinwei Long, and Bowen Zhou </div> <div class="periodical"> <em>Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2310.15477" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/TsinghuaC3I/CRaSh" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kaiyan Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: May 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-H7E2SD4PMT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-H7E2SD4PMT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"news-one-first-author-paper-is-accepted-to-emnlp-2023-see-crash",title:"One first-author paper is accepted to EMNLP 2023 (see CRaSh).",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-naacl-2024-see-pad",title:"One paper is accepted to NAACL 2024 (see PAD).",description:"",section:"News"},{id:"news-two-papers-are-accepted-to-acl-2024-one-first-author-see-cogenesis",title:"Two papers are accepted to ACL 2024 (One first-author, see CoGenesis).",description:"",section:"News"},{id:"news-one-co-first-author-paper-is-accepted-to-colm-2024-see-llm4biohypogen",title:"One co-first author paper is accepted to COLM 2024 (see LLM4BioHypoGen).",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-emnlp-2024-see-lpa",title:"One paper is accepted to EMNLP 2024 (see LPA).",description:"",section:"News"},{id:"news-one-first-author-paper-is-accepted-to-neurips-2024-d-amp-amp-b-track-see-ultramedical",title:"One first-author paper is accepted to NeurIPS 2024 D&amp;amp;B Track (see UltraMedical )....",description:"",section:"News"},{id:"news-one-paper-is-accepted-to-aaai-2025-congrats-to-xinwei",title:"One paper is accepted to AAAI 2025 (Congrats to Xinwei).",description:"",section:"News"},{id:"news-one-first-author-paper-is-accepted-to-iclr-2025-see-openprm",title:"One first-author paper is accepted to ICLR 2025 (see OpenPRM).",description:"",section:"News"},{id:"news-we-explore-compute-optimal-test-time-scaling-see-compute-optimal-tts",title:"We explore compute-optimal test-time scaling (see compute-optimal-tts ).",description:"",section:"News"},{id:"news-video-t1-is-released-which-firstly-evaluate-tts-on-video-generation-see-video-t1",title:"Video-T1 is released, which firstly evaluate TTS on video generation (see Video-T1 )....",description:"",section:"News"},{id:"news-we-release-collections-of-rl-recipes-see-awesome-rl-reasoning-recipes",title:"We release collections of RL recipes (see Awesome-RL-Reasoning-Recipes ).",description:"",section:"News"},{id:"news-we-release-test-time-reinforcement-learning-ttrl-which-investigates-reinforcement-learning-rl-on-data-without-explicit-labels-for-reasoning-tasks-in-llms-see-ttrl",title:"We release Test-time Reinforcement Learning (TTRL), which investigates Reinforcement Learning (RL) on data...",description:"",section:"News"},{id:"news-four-papers-are-accepted-to-icml-2025-congrats-to-the-collaborators",title:"Four papers are accepted to ICML 2025, congrats to the collaborators.",description:"",section:"News"},{id:"news-just-shared-our-latest-work-on-tts-rl-and-ttrl-at-qingketalk",title:"Just shared our latest work on TTS, RL and TTRL at QingkeTalk.",description:"",section:"News"},{id:"news-two-papers-are-accepted-to-acl-2025-main-congrats-to-the-collaborators",title:"Two papers are accepted to ACL 2025 Main, congrats to the collaborators.",description:"",section:"News"},{id:"news-we-are-very-excited-to-release-marti-a-framework-for-llm-based-multi-agent-reinforced-training-and-inference-see-marti",title:"We are very excited to release MARTI: A framework for LLM-based Multi-Agent Reinforced...",description:"",section:"News"},{id:"projects-project-template",title:"project template",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/template/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%68%61%6E%67-%6B%79%32%32@%6D%61%69%6C%73.%74%73%69%6E%67%68%75%61.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=3RjM7L8AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iseesaw","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/OkhayIea","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>