---
layout: about
title: about
permalink: /
subtitle: PhD Candidate, <a href='https://www.tsinghua.edu.cn/'>Tsinghua University</a>

profile:
  align: right
  image: 
  image_circular: true # crops the image to make it circular
  # more_info: >
    # <p><b>Kaiyan Zhang (张开颜)</b></p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a final-year PhD candidate at the Department of Electronic Engineering, Tsinghua University, under the guidance of Professor [Bowen Zhou](https://scholar.google.com/citations?hl=zh-CN&user=h3Nsz6YAAAAJ&view_op=list_works&sortby=pubdate). I earned B.S. (2020) and M.S. (2022) degrees in Computer Science and Technology from the Harbin Institute of Technology (HIT), where I was supervised by [Weinan Zhang](https://scholar.google.com/citations?user=DBLdEf4AAAAJ&hl=zh-CN) and [Ting Liu](https://scholar.google.com/citations?user=zyMJ1V0AAAAJ&hl=en) in the [HIT-SCIR](https://ir.hit.edu.cn/) lab.

<!-- I am open to collaborations and discussions across related areas—such as **multi-agent** ([COLM 2024](https://arxiv.org/pdf/2407.08940), [ACL 2024](https://arxiv.org/pdf/2403.03129), [Arxiv 2406](https://arxiv.org/pdf/2406.12295)), **reinforcement learning** ([Arxiv 2412 - ImplicitPRM](https://arxiv.org/pdf/2412.01981), [Arxiv 2502 - PRIME](https://arxiv.org/pdf/2502.01456)), **test-time scaling** ([ICLR 2025 - OpenPRM](https://openreview.net/forum?id=fGIqGfmgkW), [Arxiv 2502](https://arxiv.org/pdf/2502.06703?), [Arxiv 2503 - Video-T1](https://arxiv.org/pdf/2503.18942), [Arxiv 2504 - GenPRM](https://arxiv.org/pdf/2504.00891)), **test-time reinforcement learning** ([Arxiv 2504 - TTRL](https://arxiv.org/abs/2504.16084)), and **multi-agent reinforcement learning** ([GitHub 2025 - MARTI](https://github.com/TsinghuaC3I/MARTI)). I’d be happy to connect with researchers who share these interests. -->

My current passion is pushing the boundaries of domain-specific superintelligence (called [ExpertAGI](https://arxiv.org/pdf/2407.08642)), enabling AI systems to achieve expert-level reasoning and collaboration across high-value and practical scenarios. My research directions include:

- **Scalable Learning (e.g., RL):** Developing novel frameworks for scalable reinforcement learning, such as [TTRL](https://github.com/PRIME-RL/TTRL) (test-time RL with unlabeled data), [SSRL](https://github.com/TsinghuaC3I/SSRL) (self-search RL leveraging intrinsic model capabilities), [MARTI](https://github.com/TsinghuaC3I/MARTI) (multi-agent RL coordination), and [OpenPRM](https://openreview.net/pdf?id=fGIqGfmgkW) (scalable process reward modeling), all aiming to reduce supervision costs and unlock self-improving LLMs.

- **Collaborative Intelligence:** Designing mechanisms for model cooperation and synergy, including [CRaSh](https://arxiv.org/abs/2310.15477) (efficient fine-tuning via clustering and sharing), [CoGenesis](https://arxiv.org/abs/2403.03129) (secure collaboration between large and small models), [FS-Gen](https://arxiv.org/abs/2406.12295) (unified laws in collaborative decoding), and [MARTI](https://github.com/TsinghuaC3I/MARTI), to empower collective intelligence among agents.

- **Scientific Intelligence:** Applying LLMs to scientific discovery, with projects like [UltraMedical](https://github.com/TsinghuaC3I/UltraMedical) (generalist biomedical models), [hypothesis proposer](https://arxiv.org/abs/2311.05965) (autonomous scientific hypothesis generation), and [ReviewRL](https://arxiv.org/abs/2508.10308) (reinforcement learning for automated scientific review), advancing AI’s role in research and innovation.

Expect to graduate in June 2026. My CV is [here](/assets/pdf/cv.pdf).